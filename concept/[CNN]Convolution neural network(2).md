# [CNN]Convolution neural network(2)
> (이 게시물은 Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow (오렐리앙 제롱 지음, 박해선 옮김) 의 책을 참고하여 작성한 글입니다.)  
> 위 책의 p542~p559의 내용을 담고 있습니다. 
​
주제 : 합성곱 신경망에서 합성곱 층, 풀링층 구성 요소에 대해서 설명합니다.
​
---
​
## 풀링 층
​
-   계산량과 메모리 사용량을 줄인다
-   파라미터 수를 줄인다.(과대적합의 위험을 줄여준다.
-   즉, 축소본을 만드는 작업
-   풀링 뉴런은 가중치가 없다. 
-   최대 풀링 층, 평균 풀링층
-   CNN에서 몇 개 층마다 최대 풀링 층을 추가하면 전체적으로 일정 수준의 이동 불변성을 얻을 수 있다. 
-   최대 풀링은 회전과 확대, 축소에 대해 약간의 불변성을 제공한다. 
-   스트라이드를 크게 줄 수록 면적이 그만큼 작아져 입력값을 많이 잃을 수 있다. 
​
#### 최대 풀링 층
​
-   MaxPool2D 사용
-   의미 없는 값을 모두 제거하여 가장 큰 특징망 유지해 다음 층이 더욱 명확해진다. 
-   이동 불변성 제공으로 연산 비용이 적다. 
-   가장 큰 값으로 특징을 낸다. 
​

![image](https://user-images.githubusercontent.com/55094745/120575215-95d89800-c45b-11eb-8535-da195850deaf.png)
​
#### 평균 풀링 층
​
-   AvgPool2D 사용
-   특성 맵에 있는 정보를 대부분 잃는다. (파괴적임)
-   하지만 출력층에서는 유용할 수 있다. 
-   평균을 내어 특징을 낸다.
​

![image](https://user-images.githubusercontent.com/55094745/120575233-9f620000-c45b-11eb-8234-bc2bd0065bb9.png)
​
### tensorflow 구현
​
<최대 풀링 층>
​
```
output = tf.nn.max_pool(images, ksize= (1,1,1,3), strides = (1,1,1,3), padding = "valid")
```
​
ksize : 커널 사이즈 배치, 높이, 너비 차원을 따라 1이다. (1,1,1,3) 실제로 원하는 커널의 크기는 가장 마지막 부분에 작성한다. 즉, (1,1,1,3)의 커널 사이즈는 3이다. 
​
stride : 스트라이드 배치, 높이, 너비 차원이 1이다. 실제로 원하는 스트라이드의 크기는 가장 마지막 부분에 작성한다. 따라서 스트라이드의 크기는 3이다. 
​
<평균 풀링 층>
​
```
global_avg_pool = keras.layers.GloabalAvgPool2D()
```
​
---
​
## CNN 구조
​
-   합성곱 층을 몇개 쌓는다. (각각 ReLU 층을 뒤에 놓는다.)
-   풀링 층을 몇개 쌓는다. (ReLU 층을 각각 뒤에 놓는다.)
-   위에 두 부분을 layer 한 단위라고 보고 위와 같은 과정을 반복한다. (점점 이미지가 작아지지만 더 깊어진다. --> 더 많은 특성 맵을 가진다. )
-   맨 마지막 부분에는 full connected
​
![image](https://user-images.githubusercontent.com/55094745/120575254-ae48b280-c45b-11eb-9fbb-5a92c8b18214.png)
